# macros.conf

# comment
[comment(1)]
args = text
definition = ""
iseval = 1

# For Splunk 7.3.x and later, you might want to include include_reduced_buckets=t
[trackme_tstats]
definition = tstats
iseval = 0

# trackMe summary index, customise its value to use your own index naming convention, default to summary
[trackme_idx]
definition = index="trackme_summary"
iseval = 0

# trackMe metric index, customise its value depending on your preference
# default to trackme_metrics which has to be created
[trackme_metrics_idx]
definition = index="trackme_metrics"
iseval = 0

# Data source availability default monitored state
# customize this macro to change the way the monitored state is defined by default, such as conditional operations
# using the index or sourcetype naming convention

# used as the top of the populating searches
[trackme_tstats_main_filter]
definition = sourcetype!="stash" sourcetype!="*too_small"
iseval = 0

# used as the top of the populating searches for metric indexes
[trackme_mstats_main_filter]
definition = metric_name="*"
iseval = 0

[trackme_default_monitored_state]
definition = eval data_monitored_state=if(isnull(data_monitored_state), "enabled", data_monitored_state)
iseval = 0

[trackme_default_host_monitored_state]
definition = eval data_monitored_state=if(isnull(data_monitored_state), "enabled", data_monitored_state)
iseval = 0

[trackme_default_metric_host_monitored_state]
definition = eval metric_monitored_state=if(isnull(metric_monitored_state), "enabled", metric_monitored_state)
iseval = 0

[trackme_default_lag]
definition = eval data_max_lag_allowed=if(isnull(data_max_lag_allowed), "3600", data_max_lag_allowed)
iseval = 0

[trackme_default_host_lag]
definition = eval data_max_lag_allowed=if(isnull(data_max_lag_allowed), "86400", data_max_lag_allowed)
iseval = 0

[trackme_default_metric_host_lag]
definition = eval metric_max_lag_allowed=if(isnull(metric_max_lag_allowed), "300", metric_max_lag_allowed)
iseval = 0

[trackme_default_monitored_wdays]
definition = eval data_monitoring_wdays=if(isnull(data_monitoring_wdays), "auto:all_days", data_monitoring_wdays)
iseval = 0

[trackme_default_host_monitored_wdays]
definition = eval data_monitoring_wdays=if(isnull(data_monitoring_wdays), "auto:all_days", data_monitoring_wdays)
iseval = 0

[trackme_default_priority]
definition = eval priority=if(isnull(priority), "medium", priority)

# can be customized for filtering
[trackme_data_sources_filtering]
definition = search data_name=*
iseval = 0

# can be customized for date format
[trackme_date_format(1)]
args = input_field
definition = eval "$input_field$ (translated)"=strftime($input_field$, "%d/%m/%Y %H:%M")
iseval = 0

# defined pattern filter for indexers
[trackme_idx_filter]
definition = host=idx*
iseval = 0

# define the tolerance in negative seconds regarding the detection of data indexed in the future (default 30 seconds)
[trackme_future_indexing_tolerance]
definition = -600
iseval = 0

# for alerts, provides macros that can be customised if necessary to order fields upon results

[trackme_alerts_order_data_source]
definition = fields data_name, data_index, data_sourcetype, data_source_state, data_monitored_state, status_message, *
iseval = 0

[trackme_alerts_order_data_host]
definition = fields data_host, data_index, data_sourcetype, data_host_state, data_monitored_state, status_message, *
iseval = 0

[trackme_alerts_order_metric_host]
definition = fields metric_host, metric_index, metric_host_state, metric_monitored_state, status_message, *
iseval = 0

# define a filtering rule for host names, sometimes complex ingestion method that requires host Meta overwrite can fail which results in pollution of wrong hosts
# A host should match a traditional naming convention
# By default: alphanumeric chars, literal dots and hyphens, less than 100 chars
[trackme_data_host_rule_filter(1)]
args = key
definition = where match($key$, "[\w|\-|\.]") AND len($key$)<100
iseval = 0

# Evaluate the icon fields rendering
[trackme_eval_icons]
definition = fillnull value="NA" "data_last_time_seen (translated)", data_last_lag_seen, data_max_lag_allowed, data_last_ingestion_lag_seen\
| fillnull value=0 isOutlier
| eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled|training)$"), isOutlier, 0)\
| fields - system_behaviour_analytic_mode\
| eval state = "icon|" + case(\
data_source_state=="green" AND data_monitoring_level="sourcetype" AND isOutlier=0, "ico_good ico_small|icon-check|Good: data source status is green, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), and monitoring conditions are met.",\
data_source_state=="green" AND data_monitoring_level="index" AND isOutlier=0, "ico_good ico_small|icon-check|Good: data source status is green, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), therefore data monitoring level is set at index level, which complies with a max lag of " . data_max_lag_allowed . " seconds for that index.",\
data_source_state=="red" AND isOutlier=0, "ico_error ico_small|icon-close|Alert: data source status is red, monitoring conditions are not met due to lagging or interruption in the data flow, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_source_state=="red" AND isOutlier=1, "ico_error ico_small|icon-close|Alert: data source status is red, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_source_state=="orange" AND isOutlier=1, "ico_warn ico_small|icon-close|Warn: data source status is orange, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_source_state=="orange" AND isnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data source status is orange, lagging conditions are met, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . " therefore week days rules conditions are not met.",\
data_source_state=="blue" AND isnotnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_unknown ico_small|icon-close|Info: data source does not honour lagging or week days monitoring conditions therefore it is a member of a logical group named: " . object_group_name . " which is honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which complies with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
data_source_state=="orange" AND data_last_lag_seen<`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data source status is orange, detected data indexed in the future which is most likely due to timestamping misconfiguration, timezone or time synchronization issue, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . "."),\
monitoring = "icon|" + if(data_monitored_state=="enabled", "ico_good ico_small|icon-check|Enabled: data source is being actively monitored", "ico_error ico_small|icon-close|Disabled: data source monitoring is disabled")\
| rex field=state "[^\|]*\|[^\|]*\|[^\|]*\|(?<status_message>.*)"
iseval = 0

[trackme_eval_icons_host]
definition = fillnull value="NA" "data_last_time_seen (translated)", data_last_lag_seen, data_max_lag_allowed, data_last_ingestion_lag_seen\
| fillnull value=0 isOutlier\
| eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled|training)$"), isOutlier, 0)\
| fields - system_behaviour_analytic_mode\
| eval state = "icon|" + case(\
data_host_state=="green", "ico_good ico_small|icon-check|Good: data host status is green, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), and monitoring conditions are met.",\
data_host_state=="red" AND isnull(object_group_name) AND isOutlier=0, "ico_error ico_small|icon-close|Alert: data host status is red, monitoring conditions are not met due to lagging or interruption in the data flow, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_host_state=="red" AND isnull(object_group_name) AND isOutlier=1, "ico_error ico_small|icon-close|Alert: data host status is red, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_host_state=="orange" AND isnull(object_group_name) AND isOutlier=1, "ico_warn ico_small|icon-close|Warn: data host status is orange, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_host_state=="red" AND isnotnull(object_group_name), "ico_error ico_small|icon-close|Alert: data host does not honour lagging or week days monitoring conditions, in addition it is a member of a logical group named: " . object_group_name . " which is not honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which does not comply with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
data_host_state=="orange" AND isnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data host status is orange, lagging conditions are met, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . " therefore week days rules conditions are not met.",\
data_host_state=="blue" AND isnotnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_unknown ico_small|icon-close|Info: data host does not honour lagging or week days monitoring conditions therefore it is a member of a logical group named: " . object_group_name . " which is honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which complies with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
data_host_state=="orange" AND data_last_lag_seen<`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data source status is orange, detected data indexed in the future which is most likely due to timestamping misconfiguration, timezone or time synchronization issue, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . "."),\
monitoring = "icon|" + if(data_monitored_state=="enabled", "ico_good ico_small|icon-check|Enabled: data host is being actively monitored", "ico_error ico_small|icon-close|Disabled: data host monitoring is disabled")\
| rex field=state "[^\|]*\|[^\|]*\|[^\|]*\|(?<status_message>.*)"
iseval = 0

[trackme_eval_icons_metric_host]
definition = eval state = "icon|" + case(\
metric_host_state=="green", "ico_good ico_small|icon-check|Good: metric host status is green, latest data available is " . 'last time' . " (" . metric_last_lag_seen . " seconds from now)",\
metric_host_state=="red" AND isnull(object_group_name), "ico_error ico_small|icon-close|Alert: metric host status is red, lagging monitoring conditions are not met, latest data available is " . 'last time' . " (" . metric_last_lag_seen . " seconds from now)",\
metric_host_state=="red" AND isnotnull(object_group_name), "ico_error ico_small|icon-close|Alert: metric host does not honour lagging conditions, in addition it is a member of a logical group named: " . object_group_name . " which is not honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which does not comply with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
metric_host_state=="blue" AND isnotnull(object_group_name), "ico_unknown ico_small|icon-close|Info: metric host does not honour lagging conditions therefore it is a member of a logical group named: " . object_group_name . " which is honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which complies with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)"),\
monitoring = "icon|" + if(metric_monitored_state=="enabled", "ico_good ico_small|icon-check|Enabled: metric host is being actively monitored", "ico_error ico_small|icon-close|Disabled: metric host monitoring is disabled")\
| rex field=state "[^\|]*\|[^\|]*\|[^\|]*\|(?<status_message>.*)"
iseval = 0

[trackme_eval_icons_metric_host_state_only]
definition = eval state = "icon|" + case(metric_host_state=="green", "ico_good ico_small|icon-check|Up: metric category is available and marked as green due to monitoring rules being met (metric last time seen: " . 	metric_last_time . ", " . metric_current_lag_sec . " seconds from now, which complies with a lagging configured of " . metric_max_lag_allowed . "seconds.)",\
metric_host_state=="red", "ico_error ico_small|icon-close|Down: metric category is not available and therefore marked as down due to rules monitoring (metric last time seen: " . 	metric_last_time . ", " . metric_current_lag_sec . " seconds from now, which does not comply with a lagging configured of " . metric_max_lag_allowed . " seconds.)")
iseval = 0

[trackme_eval_icons_flip]
definition = eval object_previous_state = "icon|" + case(\
object_previous_state=="green", "ico_good ico_small|icon-check|Up: object is available and marked as green due to monitoring rules being met",\
object_previous_state=="red", "ico_error ico_small|icon-close|Down: object is not available or marked as down due to rules monitoring",\
object_previous_state=="orange", "ico_warn ico_small|icon-close|Warn: object is not available but marked as warn due to monitoring rules",\
object_previous_state=="blue", "ico_unknown ico_small|icon-close|Info: object is not available therefore it is member of a logical group which monitoring rules are met",\
object_previous_state=="discovered", "ico_unknown ico_small|icon-close|Info: object was discovered and added to the collections"),\
object_state = "icon|" + case(object_state=="green", "ico_good ico_small|icon-check|Up: object is available and marked as green due to monitoring rules being met",\
object_state=="red", "ico_error ico_small|icon-close|Down: object is not available or marked as down due to rules monitoring",\
object_state=="orange", "ico_warn ico_small|icon-close|Warn: object is not available but marked as warn due to monitoring rules",\
object_state=="blue", "ico_unknown ico_small|icon-close|Info: object is not available therefore it is member of a logical group which monitoring rules are met")
iseval = 0

[trackme_eval_icons_audit_changes]
definition = eval action_icon = "icon|" + case(\
action=="success", "ico_good ico_small|icon-check|Up: change action was successful",\
action!="success", "ico_error ico_small|icon-close|Down: change action was refused or its status is unknown")
iseval = 0

# Evaluate the data source status
[trackme_eval_data_source_state]
definition = eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval system_behaviour_analytic_mode=if(system_behaviour_analytic_mode="enabled" OR system_behaviour_analytic_mode="training" OR system_behaviour_analytic_mode="disabled", system_behaviour_analytic_mode, "enabled")\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled|training)$"), isOutlier, 0)\
| eval data_source_state=case(\
data_monitoring_level="index", if(data_last_lag_seen_idx>data_max_lag_allowed, "red", "green"),\
data_monitoring_level="sourcetype", if(data_last_lag_seen>data_max_lag_allowed OR data_last_ingestion_lag_seen>data_max_lag_allowed OR (isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="enabled"), "red", "green"))\
| eval data_source_state=if(isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="training", "orange", data_source_state)\
| fields - system_behaviour_analytic_mode\
| eval current_wday=strftime(now(), "%a")\
| eval current_wday_no=strftime(now(), "%w")\
| eval data_source_state=if(match(data_monitoring_wdays, "^(auto|manual):all_days") AND match(current_wday, ".*") AND data_source_state="red", "red", data_source_state)\
| eval data_source_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-friday") AND match(current_wday, "Sat|Sun") AND data_source_state="red", "orange", data_source_state)\
| eval data_source_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-saturday") AND match(current_wday, "Sun") AND data_source_state="red", "orange", data_source_state)\
| rex field=data_monitoring_wdays "^(manual|auto)\:(?<data_monitoring_wdays_no>\d.*)"\
| makemv delim="," data_monitoring_wdays_no\
| eval data_source_state=if(isnotnull(data_monitoring_wdays_no) AND current_wday_no!=data_monitoring_wdays_no AND data_source_state="red", "orange", data_source_state)\
| eval data_source_state=if(isnull(data_last_time_seen), "red", data_source_state)\
| eval data_source_state=if(data_last_lag_seen<`trackme_future_indexing_tolerance`, "orange", data_source_state)\
| fields - current_*, data_monitoring_wdays_no

# Evaluate the host status
[trackme_eval_data_host_state]
definition = eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval system_behaviour_analytic_mode=if(system_behaviour_analytic_mode="enabled" OR system_behaviour_analytic_mode="training" OR system_behaviour_analytic_mode="disabled", system_behaviour_analytic_mode, "enabled")\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled|training)$"), isOutlier, 0)\
| eval data_host_state=if(data_last_lag_seen>data_max_lag_allowed OR (isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="enabled"), "red", "green")\
| eval data_host_state=if(isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="training", "orange", data_host_state)\
| fields - system_behaviour_analytic_mode\
| eval current_wday=strftime(now(), "%a")\
| eval current_wday_no=strftime(now(), "%w")\
| eval data_host_state=if(match(data_monitoring_wdays, "^(auto|manual):all_days") AND match(current_wday, ".*") AND data_host_state="red", "red", data_host_state)\
| eval data_host_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-friday") AND match(current_wday, "Sat|Sun") AND data_host_state="red", "orange", data_host_state)\
| eval data_host_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-saturday") AND match(current_wday, "Sun") AND data_host_state="red", "orange", data_host_state)\
| rex field=data_monitoring_wdays "^(manual|auto)\:(?<data_monitoring_wdays_no>\d.*)"\
| makemv delim="," data_monitoring_wdays_no\
| eval data_host_state=if(isnotnull(data_monitoring_wdays_no) AND current_wday_no!=data_monitoring_wdays_no AND data_host_state="red", "orange", data_host_state)\
| eval data_host_state=if(isnull(data_last_time_seen), "red", data_host_state)\
| eval data_host_state=if(data_last_lag_seen<`trackme_future_indexing_tolerance`, "orange", data_host_state)\
| fields - current_*, data_monitoring_wdays_no

# define flipping statuses and output to the collection
[trackme_get_flip(4)]
definition = eval hasFlipped=if($previous_state$!=$state$ AND isnull(simulation), 0, 1) | eval hasFlipped=if(isnum(hasFlipped), hasFlipped, 0)\
| eval latest_flip_time=if(hasFlipped=0, now(), latest_flip_time)\
| eval latest_flip_state=if(hasFlipped=0, $state$, latest_flip_state)\
| eval object_state=$state$, object_previous_state=$previous_state$\
| eval object=$key$, object_category=case(isnotnull(data_name), "data_source", isnotnull(data_host), "data_host", isnotnull(metric_host), "metric_host")\
| appendpipe [ | where hasFlipped==0 | eval time=now(), result = strftime(now(), "%d/%m/%Y %H:%M:%S") . ", object=" . $key$ . " has flipped from previous_state=" . $previous_state$ . " to state=" . $state$ | outputlookup $collection$ append=t | eval rectype="0"]\
| appendpipe [ | where hasFlipped==1 | eval time=now(), rectype="1"]\
| where isnotnull(rectype) | fields - hasFlipped, rectype, time
args = state, previous_state, key, collection
iseval = 0

# manage flip temp collection and collect
[trackme_collect_flip(1)]
definition = inputlookup append=t $collection$ | where isnotnull(object)\
| fields time, object, object_category, result, object_previous_state, object_state | eval _time=time\
| `trackme_sumarycollect("flip_state_change_tracking")`\
| where noop="true"\
| outputlookup $collection$
args = collection
iseval = 0

# data source macro abstract
[trackme_data_source_tracker_abstract]
definition = `comment("#### define the ingestion lag versus now, and a flag field defining an online status any results from live tstats ####")`\
| eval data_last_lag_seen=now()-data_last_time_seen, data_source_is_online="true"\
\
`comment("#### some rename to keep the same convention across other trackers ####")`\
| rename data_last_ingestion_lag_seen as live_data_last_ingestion_lag_seen, data_last_ingest as live_data_last_ingest, data_first_time_seen as live_data_first_time_seen, data_last_time_seen as live_data_last_time_seen, data_last_lag_seen as live_data_last_lag_seen, data_eventcount as live_data_eventcount\
\
`comment("#### appends the current collection entries ####")`\
\
| inputlookup append=t trackme_data_source_monitoring | eval key=_key\
| stats first(*) as "*" by data_name\
\
`comment("#### manage live information ####")`\
| eval data_last_ingest=if(isnotnull(live_data_last_ingest), live_data_last_ingest, data_last_ingest)\
| eval data_first_time_seen=if(isnotnull(data_first_time_seen), data_first_time_seen, live_data_first_time_seen)\
| eval data_last_time_seen=if(isnotnull(live_data_last_time_seen), live_data_last_time_seen, data_last_time_seen)\
| eval data_last_lag_seen=if(isnotnull(live_data_last_lag_seen), live_data_last_lag_seen, data_last_lag_seen)\
| eval data_last_ingestion_lag_seen=if(isnotnull(live_data_last_ingestion_lag_seen), live_data_last_ingestion_lag_seen, data_last_ingestion_lag_seen)\
| eval data_eventcount=if(isnotnull(live_data_eventcount), live_data_eventcount, 0)\
| fields - live_*\
\
`comment("#### manage previous values ####")`\
| rename data_source_state as data_previous_source_state, data_tracker_runtime as data_previous_tracker_runtime\
\
`comment("#### if the key is null, this is the first time we see this source and it will be added to the collection, create a key ####")`\
| eval key=if(isnull(key), md5(data_name), key)\
\
`comment("#### apply default policies ####")`\
| `trackme_default_monitored_state`\
| `trackme_default_lag`\
| `trackme_default_monitored_wdays`\
| `trackme_default_priority`\
\
`comment("#### handle override lagging class ####")`\
| eval data_override_lagging_class=if(isnull(data_override_lagging_class) OR data_override_lagging_class="null", "false", data_override_lagging_class)\
\
`comment("#### lookup any defined rule for max lagging based on index or sourcetype ####")`\
| lookup trackme_custom_lagging_definition name as data_index OUTPUTNEW value as data_custom_max_lag_allowed\
| lookup trackme_custom_lagging_definition name as data_sourcetype OUTPUTNEW value as data_custom_max_lag_allowed\
\
`comment("#### conditionally handle data_max_lag_allowed ####")`\
| eval data_max_lag_allowed	=if(isnum(data_custom_max_lag_allowed) AND data_override_lagging_class!="true", data_custom_max_lag_allowed, data_max_lag_allowed)\
| fields - data_custom_max_lag_allowed\
\
`comment("#### exclude any permanent deletion stored in the trackme_audit_change lookup ####")`\
| search NOT [ | inputlookup trackme_audit_changes | where action="success" AND change_type="delete permanent" | eval _time=time/1000 | where _time>relative_time(now(), "-7d") | table object | dedup object | sort limit=0 object | rename object as data_name ]\
\
`comment("#### conditionally define data_monitoring_level ####")`\
| eval data_monitoring_level=if(isnull(data_monitoring_level), "sourcetype", data_monitoring_level)\
\
`comment("#### calculate last time seen and lag per index ####")`\
| eventstats max(data_last_time_seen) as data_last_time_seen_idx, min(data_last_lag_seen) as data_last_lag_seen_idx by data_index\
\
`comment("#### filter sources ####")`\
| `trackme_data_sources_filtering`\
\
`comment("#### define the object_category field which is used by further lookup operations ####")`\
| eval object_category="data_source"\
\
`comment("#### retrieve summary investigator analytic ####")`\
| inputlookup append=t trackme_summary_investigator_volume_outliers\
| eval data_name=if(isnull(data_name) AND object_category="data_source", object, data_name)\
| where isnotnull(data_name)\
| stats first(*) as "*" by data_name\
| where isnotnull(key)\
\
`comment("#### fillnull for OutlierMinEventCount, isOutlier ####")`\
| fillnull value=0 OutlierMinEventCount\
| fillnull value=0 isOutlier\
\
`comment("#### OutlierMinEventCount needs to be equal to 0 if set to non numerical value ####")`\
| eval OutlierMinEventCount=if(isnum(OutlierMinEventCount), OutlierMinEventCount, 0)\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Define the behaviour for alerting on upper bound ####")`\
| eval OutlierAlertOnUpper=if(isnotnull(OutlierAlertOnUpper), OutlierAlertOnUpper, `trackme_default_outlier_alert_on_upper`)\
\
`comment("#### Define the default period for Outliers calculations ####")`\
| eval OutlierTimePeriod=if(isnotnull(OutlierTimePeriod), OutlierTimePeriod, `trackme_default_outlier_period`)\
\
`comment("#### Define the default value for Outliers span ####")`\
| eval OutlierSpan=if(isnotnull(OutlierSpan), OutlierSpan, "5m")\
\
`comment("#### define a status for enable_behaviour_analytic ####")`\
| eval enable_behaviour_analytic=if(isnull(enable_behaviour_analytic) OR enable_behaviour_analytic="", `trackme_default_enable_behaviour_analytic`, enable_behaviour_analytic)\
\
`comment("#### define isOutlier status ####")`\
| `trackme_isOutlier_status`\
\
`comment("#### eval state source ####")`\
| `trackme_eval_data_source_state`\
\
`comment("#### data_tracker_runtime is now ####")`\
| eval data_tracker_runtime=now()\
\
`comment("#### conditional verifications ####")`\
| eval data_previous_source_state=if(isnull(data_previous_source_state), "discovered", data_previous_source_state)\
| eval data_previous_tracker_runtime=if(isnull(data_previous_tracker_runtime), now(), data_previous_tracker_runtime)\
| eval latest_flip_state=if(isnull(latest_flip_state), data_previous_source_state, latest_flip_state)\
| eval latest_flip_time=if(isnull(latest_flip_time), data_previous_tracker_runtime, latest_flip_time)\
\
| where isnotnull(data_last_time_seen)\
| eval data_last_lag_seen=if(data_source_is_online="true", data_last_lag_seen, now()-data_last_time_seen)\
\
`comment("#### auto disable monitoring status based on policies ####")`\
| eval data_monitored_state=if(data_last_time_seen<=`trackme_auto_disablement_period`, "disabled", data_monitored_state)
iseval = 0

[trackme_data_host_tracker_abstract]
definition = eval host=upper(host)\
\
`comment("#### host level calculations before loading the collection content")`\
| eventstats sum(data_eventcount) as data_eventcount, max(data_custom_max_lag_allowed_per_index) as data_custom_max_lag_allowed_per_index, max(data_custom_max_lag_allowed_per_sourcetype) as data_custom_max_lag_allowed_per_sourcetype by host\
\
| inputlookup append=t trackme_host_monitoring\
| eval host=if(isnull(host), data_host, host)\
| eval sourcetype=if(isnull(sourcetype), data_sourcetype, sourcetype)\
| eval index=if(isnull(index), data_index, index)\
| makemv delim="," index\
| makemv delim="," sourcetype\
| mvexpand index\
| mvexpand sourcetype\
\
`comment("#### lagging policies ####")`\
| lookup trackme_custom_lagging_definition name as index OUTPUTNEW value as data_custom_max_lag_allowed_per_index\
| lookup trackme_custom_lagging_definition name as sourcetype OUTPUTNEW value as data_custom_max_lag_allowed_per_sourcetype\
\
`comment("#### for any match within the lagging policy, the highest lagging value has the precedence ####")`\
| eval data_custom_max_lag_allowed=case(\
isnum(data_custom_max_lag_allowed_per_index) AND isnum(data_custom_max_lag_allowed_per_sourcetype) AND data_custom_max_lag_allowed_per_index>data_custom_max_lag_allowed_per_sourcetype, data_custom_max_lag_allowed_per_index,\
isnum(data_custom_max_lag_allowed_per_index) AND isnum(data_custom_max_lag_allowed_per_sourcetype) AND data_custom_max_lag_allowed_per_sourcetype>data_custom_max_lag_allowed_per_index, data_custom_max_lag_allowed_per_sourcetype,\
isnum(data_custom_max_lag_allowed_per_index), data_custom_max_lag_allowed_per_index,\
isnum(data_custom_max_lag_allowed_per_sourcetype), data_custom_max_lag_allowed_per_sourcetype)\
| fields - data_custom_max_lag_allowed_per_index, data_custom_max_lag_allowed_per_sourcetype\
\
`comment("#### perform intermediate calculation table ####")`\
| stats max(data_last_ingest) as data_last_ingest, min(data_first_time_seen) as data_first_time_seen,\
max(data_last_time_seen) as data_last_time_seen, avg(data_last_ingestion_lag_seen) as data_last_ingestion_lag_seen,\
values(index) as data_index, values(sourcetype) as data_sourcetype,\
max(data_custom_max_lag_allowed) as data_custom_max_lag_allowed, first(*) as "*" by host\
| eval data_last_ingestion_lag_seen=round(data_last_ingestion_lag_seen, 0)\
\
`comment("#### define the ingestion lag versus now, and a flag field defining an online status any results from live tstats ####")`\
| eval data_last_lag_seen=now()-data_last_time_seen, data_host_is_online="true"\
\
`comment("#### rename host and upper case ####")`\
| rename host as data_host | eval data_host=upper(data_host)\
\
`comment("#### manage previous values ####")`\
| rename data_host_state as data_previous_host_state, data_tracker_runtime as data_previous_tracker_runtime\
\
`comment("#### exclude any permanent deletion stored in the trackme_audit_change lookup ####")`\
| search NOT [ | inputlookup trackme_audit_changes | where action="success" AND change_type="delete permanent" | eval _time=time/1000 | where _time>relative_time(now(), "-7d") | table object | dedup object | sort limit=0 object | rename object as data_host ]\
\
`comment("#### if the key is null, this is the first time we see this source and it will be added to the collection, create a key ####")`\
| eval key=if(isnull(key), md5(data_host), key)\
\
`comment("#### apply various macro defining default values and policies ####")`\
| `trackme_default_host_monitored_state`\
| `trackme_default_host_lag`\
| `trackme_default_host_monitored_wdays`\
| `trackme_default_priority`\
\
`comment("#### if data_override_lagging_class is defined ####")`\
| eval data_override_lagging_class=if(isnull(data_override_lagging_class) OR data_override_lagging_class="null", "false", data_override_lagging_class)\
\
`comment("#### additional conditional operations on data_max_lag_allowed depending on policies ####")`\
| eval data_max_lag_allowed	=if(isnum(data_custom_max_lag_allowed) AND data_override_lagging_class!="true", data_custom_max_lag_allowed, data_max_lag_allowed)\
\
`comment("#### create a comma separated list of known indexes and sourcetype for live/lookup merge in next phase ####")`\
| eval data_index=mvjoin(data_index, ","), data_sourcetype=mvjoin(data_sourcetype, ",")\
\
`comment("#### define the object_category field which is used by further lookup operations ####")`\
| eval object_category="data_host"\
\
`comment("#### retrieve summary investigator analytic ####")`\
| inputlookup append=t trackme_summary_investigator_volume_outliers\
| eval data_host=if(isnull(data_host) AND object_category="data_host", object, data_host)\
| where isnotnull(data_host)\
| stats first(*) as "*" by data_host\
| where isnotnull(key)\
\
`comment("#### fillnull for OutlierMinEventCount, isOutlier ####")`\
| fillnull value=0 OutlierMinEventCount\
| fillnull value=0 isOutlier\
\
`comment("#### OutlierMinEventCount needs to be equal to 0 if set to non numerical value ####")`\
| eval OutlierMinEventCount=if(isnum(OutlierMinEventCount), OutlierMinEventCount, 0)\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Define the behaviour for alerting on upper bound ####")`\
| eval OutlierAlertOnUpper=if(isnotnull(OutlierAlertOnUpper), OutlierAlertOnUpper, `trackme_default_outlier_alert_on_upper`)\
\
`comment("#### Define the default period for Outliers calculations ####")`\
| eval OutlierTimePeriod=if(isnotnull(OutlierTimePeriod), OutlierTimePeriod, `trackme_default_outlier_period`)\
\
`comment("#### Define the default value for Outliers span ####")`\
| eval OutlierSpan=if(isnotnull(OutlierSpan), OutlierSpan, "5m")\
\
`comment("#### define a status for enable_behaviour_analytic ####")`\
| eval enable_behaviour_analytic=if(isnull(enable_behaviour_analytic) OR enable_behaviour_analytic="", `trackme_default_enable_behaviour_analytic`, enable_behaviour_analytic)\
\
`comment("#### define isOutlier status ####")`\
| `trackme_isOutlier_status`\
\
`comment("#### define state ####")`\
| `trackme_eval_data_host_state`\
\
`comment("#### source group feature ####")`\
| `trackme_data_host_group_lookup`\
\
`comment("#### define data_tracker_runtime ####")`\
| eval data_tracker_runtime=now()\
\
`comment("#### conditional verifications ####")`\
| eval data_previous_host_state=if(isnull(data_previous_host_state), "discovered", data_previous_host_state)\
| eval data_previous_tracker_runtime=if(isnull(data_previous_tracker_runtime), now(), data_previous_tracker_runtime)\
| eval latest_flip_state=if(isnull(latest_flip_state), data_previous_host_state, latest_flip_state)\
| eval latest_flip_time=if(isnull(latest_flip_time), data_previous_tracker_runtime, latest_flip_time)\
\
| where isnotnull(data_last_time_seen)\
| eval data_last_lag_seen=if(data_host_is_online="true", data_last_lag_seen, now()-data_last_time_seen)\
\
`comment("#### apply host filtering ####")`\
| `trackme_data_host_rule_filter(data_host)`\
\
`comment("#### auto disable monitoring status based on policies ####")`\
| eval data_monitored_state=if(data_last_time_seen<=`trackme_auto_disablement_period`, "disabled", data_monitored_state)
iseval = 0

# Automatic monitored_state disablement based on latest event received
[trackme_auto_disablement_period]
definition = relative_time(now(), "-45d")
iseval = 0

# Evaluate the per metric entity status (metric_category)
[trackme_eval_metric_category_state]
definition = eval detail_metric_host_state=if(detail_metric_current_lag_sec>detail_metric_max_lag_allowed, "red", "green")

# Evaluate the metric host status
[trackme_eval_metric_host_state]
definition = eval metric_host_state=if(match(metric_details, "metric_host_state=red"), "red", "green")

# For blacklists, detect if blacklist entry is a regular expression
[detect_rex(1)]
definition = eval is_rex=if(match($key$, "[\\\|\?|\$|\^|\[|\]|\{|\}|\+]"), "true", "false")\
| eval is_rex=if(match($key$, "\.\*"), "true", is_rex)
args = key
iseval = 0

# Blacklist exclusion for regular expression support
[apply_blacklist_rex(2)]
definition = | inputlookup $collection$ | `detect_rex($key$)` | where is_rex="true" | table $key$ | format\
| fields search\
| rex field=search mode=sed "s/$key$=/match($key$, /g"\
| rex field=search mode=sed "s/\( match/match/g"\
| rex field=search mode=sed "s/NOT \(\)/match($key$, \"null\")/g" | return $search
args = collection, key
iseval = 0

[apply_blacklist_rex(3)]
definition = | inputlookup $collection$ | `detect_rex($key$)` | where is_rex="true" | table $key$ | rename $key$ as $newkey$ | format\
| fields search\
| rex field=search mode=sed "s/$newkey$=/match($newkey$, /g"\
| rex field=search mode=sed "s/\( match/match/g"\
| rex field=search mode=sed "s/NOT \(\)/match($newkey$, \"null\")/g" | return $search
args = collection, key, newkey
iseval = 0

# Blacklist exclusions
[apply_data_source_blacklists_data_retrieve]
definition = [ | inputlookup trackme_data_source_monitoring_blacklist_index\
| getlistdef fieldname=word_count pattern="\\w+" outname=data_index data_index\
| rex max_match=0 "\(\'data_index\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index | `detect_rex(index)` | where is_rex="false" | fields - is_rex | where NOT match(index, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(index=*)", "NOT " . search) ]\
\
[ | inputlookup trackme_data_source_monitoring_blacklist_sourcetype\
| getlistdef fieldname=word_count pattern="\\w+" outname=data_sourcetype data_sourcetype\
| rex max_match=0 "\(\'data_sourcetype\'\, \'(?<sourcetype>[^\']*)\'\)" | fields - _raw | mvexpand sourcetype | `detect_rex(sourcetype)` | where is_rex="false" | fields - is_rex | where NOT match(sourcetype, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(sourcetype=*)", "NOT " . search) ]\
\
[ | inputlookup trackme_data_source_monitoring_blacklist_host\
| getlistdef fieldname=word_count pattern="\\w+" outname=data_host data_host\
| rex max_match=0 "\(\'data_host\'\, \'(?<host>[^\']*)\'\)" | fields - _raw | mvexpand host | `detect_rex(host)` | where is_rex="false" | fields - is_rex | where NOT match(host, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(host=*)", "NOT " . search) ]
iseval = 0

[apply_data_host_blacklists_data_retrieve]
definition = [ | inputlookup trackme_data_host_monitoring_blacklist_index\
| getlistdef fieldname=word_count pattern="\\w+" outname=data_index data_index\
| rex max_match=0 "\(\'data_index\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index | `detect_rex(index)` | where is_rex="false" | fields - is_rex | where NOT match(index, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(index=*)", "NOT " . search) ]\
\
[ | inputlookup trackme_data_host_monitoring_blacklist_sourcetype\
| getlistdef fieldname=word_count pattern="\\w+" outname=data_sourcetype data_sourcetype\
| rex max_match=0 "\(\'data_sourcetype\'\, \'(?<sourcetype>[^\']*)\'\)" | fields - _raw | mvexpand sourcetype | `detect_rex(sourcetype)` | where is_rex="false" | fields - is_rex | where NOT match(sourcetype, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(sourcetype=*)", "NOT " . search) ]\
\
[ | inputlookup trackme_data_host_monitoring_blacklist_host\
| getlistdef fieldname=word_count pattern="\\w+" outname=data_host data_host\
| rex max_match=0 "\(\'data_host\'\, \'(?<host>[^\']*)\'\)" | fields - _raw | mvexpand host | `detect_rex(host)` | where is_rex="false" | fields - is_rex | where NOT match(host, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(host=*)", "NOT " . search) ]
iseval = 0

[apply_metric_host_blacklists_data_retrieve]
definition = [ | inputlookup trackme_metric_host_monitoring_blacklist_index\
| getlistdef fieldname=word_count pattern="\\w+" outname=metric_index metric_index\
| rex max_match=0 "\(\'metric_index\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index | `detect_rex(index)` | where is_rex="false" | fields - is_rex | where NOT match(index, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(index=*)", "NOT " . search) ]\
\
[ | inputlookup trackme_metric_host_monitoring_blacklist_host\
| getlistdef fieldname=word_count pattern="\\w+" outname=metric_host metric_host\
| rex max_match=0 "\(\'metric_host\'\, \'(?<host>[^\']*)\'\)" | fields - _raw | mvexpand host | `detect_rex(host)` | where is_rex="false" | fields - is_rex | where NOT match(host, "^\*$") | format | eval search=if(match(search, "NOT \(\)"), "(host=*)", "NOT " . search) ]
iseval = 0

[apply_data_source_blacklists]
definition = search NOT [ | inputlookup trackme_data_source_monitoring_blacklist_index | `detect_rex(data_index)` | where is_rex="false" | table data_index ] NOT [ | inputlookup trackme_data_source_monitoring_blacklist_sourcetype | `detect_rex(data_sourcetype)` | where is_rex="false" | table data_sourcetype ]\
| where NOT [ `apply_blacklist_rex(trackme_data_source_monitoring_blacklist_index, data_index)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_source_monitoring_blacklist_sourcetype, data_sourcetype)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_source_monitoring_blacklist_host, data_host)` ]
iseval = 0

[apply_data_host_blacklists]
definition = search NOT [ | inputlookup trackme_data_host_monitoring_blacklist_host | `detect_rex(data_host)` | where is_rex="false" | table data_host ] NOT [ | inputlookup trackme_data_host_monitoring_blacklist_index | `detect_rex(data_index)` | where is_rex="false" | table data_index ] NOT [ | inputlookup trackme_data_host_monitoring_blacklist_sourcetype | `detect_rex(data_sourcetype)` | where is_rex="false" | table data_sourcetype ]\
| where NOT [ `apply_blacklist_rex(trackme_data_host_monitoring_blacklist_index, data_index)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_host_monitoring_blacklist_sourcetype, data_sourcetype)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_host_monitoring_blacklist_host, data_host)` ]
iseval = 0

[apply_metric_host_blacklists]
definition = search NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_host | `detect_rex(metric_host)` | where is_rex="false" | table metric_host ] NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_index | `detect_rex(metric_index)` | where is_rex="false" | table metric_index ]\
| where NOT [ `apply_blacklist_rex(trackme_metric_host_monitoring_blacklist_host, metric_host)` ]\
| where NOT [ `apply_blacklist_rex(trackme_metric_host_monitoring_blacklist_index, metric_index)` ]
iseval = 0

[apply_metric_host_blacklists_metric_category]
definition = search NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_metric_category | table metric_category ]
iseval = 0

[apply_metric_host_blacklists_detail_metric_category]
definition = search NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_metric_category | table metric_category ] NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_metric_category | table metric_category | rename metric_category as detail_metric_category ]
iseval = 0

# Default retention for audit changes, in relative time format.
# Default is 90d
[trackme_audit_changes_retention]
definition =  where _time>relative_time(now(), "-90d")
iseval = 0

# Default priority levels for OOTB alerts
[trackme_alerts_priority]
definition = priority="medium" OR priority="high"
iseval = 0

# whitelist indexes
[trackme_get_idx_whitelist(2)]
args = lookup, outname
definition = [ | inputlookup $lookup$\
| getlistdef fieldname=word_count pattern="\\w+" outname=$outname$ $outname$\
| rex max_match=0 "\(\'$outname$\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index ]
iseval = 0

[trackme_get_idx_whitelist_searchtime(2)]
args = lookup, outname
definition = [ | inputlookup $lookup$\
| getlistdef fieldname=word_count pattern="\\w+" outname=$outname$ $outname$\
| rex max_match=0 "\(\'$outname$\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index | rename index as $outname$ ]
iseval = 0

# TrackMe data source identity card
[trackme_get_identity_card(1)]
args = key
definition = lookup trackme_sources_knowledge object as $key$\
| eval doc_link=if(isnull(doc_link), "null", doc_link), doc_note=if(isnull(doc_note), "null", doc_note)
iseval = 0

# Ack default duration in seconds
[trackme_ack_default_duration]
definition = 86400
iseval = 0

# Ack add
[trackme_ack_add(3)]
definition = makeresults\
| eval object="$object$", object_category="$object_category$"\
| rename _time as ack_mtime\
| eval ack_expiration=now()+($ack_duration$), ack_state="active"\
| fields object, object_category, ack_mtime, ack_expiration, ack_state\
| append [ | inputlookup trackme_alerts_ack | where NOT (object="$object$" AND object_category="$object_category$") ]\
| outputlookup trackme_alerts_ack
args = object, object_category, ack_duration
iseval = 0

# Ack get
[trackme_ack_get(2)]
definition = makeresults\
| eval object="$object$", object_category="$object_category$"\
| lookup trackme_alerts_ack object object_category OUTPUT | rename _key as keyid\
| table keyid, object, object_category, ack_mtime, ack_expiration, ack_state | fields - _time\
| eval ack_state=if(isnull(ack_state), "inactive", ack_state)\
| eval ack_mtime=if(ack_state="active", strftime(ack_mtime, "%c"), "N/A"), ack_expiration=if(ack_state="active", strftime(ack_expiration, "%c"), "N/A")
args = object, object_category
iseval = 0

# Ack lookup
[trackme_ack_lookup(2)]
definition = eval object_category="$object_category$" | lookup trackme_alerts_ack object as $object$ object_category | eval ack_state=if(isnull(ack_state), "inactive", ack_state) | where ack_state!="active" | fields - ack_*
args = object, object_category
iseval = 0

[trackme_ack_lookup_main(1)]
definition = lookup trackme_alerts_ack object as $object$ object_category | eval ack_state=if(isnull(ack_state), "inactive", ack_state)\
| eval state = if(ack_state="active", "icon|" + "ico_ack ico_small|icon-visible|Acknowledged: " . status_message, state)
args = object
iseval = 0

# Ack disable
[trackme_ack_disable(1)]
definition = inputlookup trackme_alerts_ack | eval keyid=_key\
| eval ack_state=if(keyid="$keyid$", "inactive", ack_state)\
| eval ack_expiration=if(ack_state="inactive", "N/A", ack_expiration), ack_mtime=if(ack_state="inactive", "N/A", ack_mtime) | fields keyid, *\
| outputlookup append=t trackme_alerts_ack key_field=keyid
args = keyid
iseval = 0

# Logical group for data host monitoring
[trackme_data_host_group_lookup]
definition = eval object_category="data_host" | lookup trackme_logical_group object_group_members as data_host OUTPUTNEW _key as object_group_key, object_group_name, object_group_min_green_percent\
| eventstats count as object_group_members_count, min(data_last_lag_seen) as object_group_last_lag_seen, count(eval(data_host_state="red")) as object_group_members_red by object_group_key, object_group_name\
| eval object_group_green_percent=100-(object_group_members_red/object_group_members_count*100)\
| eval data_host_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND data_host_state!="green" AND object_group_green_percent>=object_group_min_green_percent, "blue", data_host_state)\
| eval object_group_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND object_group_green_percent>=object_group_min_green_percent, "green", "red")
iseval = 0

# Logical group for metric host monitoring
[trackme_metric_host_group_lookup]
definition = eval object_category="metric_host" | lookup trackme_logical_group object_group_members as metric_host OUTPUTNEW _key as object_group_key, object_group_name, object_group_min_green_percent\
| eventstats count as object_group_members_count, min(metric_last_lag_seen) as object_group_last_lag_seen, count(eval(metric_host_state="red")) as object_group_members_red by object_group_key, object_group_name\
| eval object_group_green_percent=100-(object_group_members_red/object_group_members_count*100)\
| eval metric_host_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND metric_host_state!="green" AND object_group_green_percent>=object_group_min_green_percent, "blue", metric_host_state)\
| eval object_group_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND object_group_green_percent>=object_group_min_green_percent, "green", "red")
iseval = 0

# Load audit flip collection for SLA compliance

[trackme_get_sla_pct_per_entity(5)]
definition = `trackme_idx` source="flip_state_change_tracking" (object_category="$object_category$" AND object="$object$")\
| sort limit=0 _time\
| table _time, object, object_category, result, object_previous_state, object_state\
| eval order="2"\
| append [ | inputlookup $collection$ where (object_category="$object_category$" AND object="$object$") | rename $object_fieldname$ as object | fields object_category, object, $first_seen_fieldname$ | eval $first_seen_fieldname$=if($first_seen_fieldname$>relative_time(now(),"-90d@d"), $first_seen_fieldname$, relative_time(now(),"-90d@d")) | rename $first_seen_fieldname$ as _time | eval object_previous_state="green", object_state="green", result="initiate table", order="1" ]\
| sort limit=0 order\
| fields - order\
| sort limit=0 _time\
| streamstats count as number_entry by object, object_category\
| eventstats count as number_total by object, object_category\
| eventstats range(_time) as range by object_category, object\
| eval range=if(number_entry=number_total, now()-_time, range)\
| eval duration=tostring(range, "duration")\
| eval duration_good=case(object_state="green" OR object_state="info", range)\
| eval duration_bad=case(object_state!="green" AND object_state!="info", range)\
| stats sum(duration_good) as duration_good, sum(duration_bad) as duration_bad by object, object_category\
| eval duration_good=if(isnum(duration_good), duration_good, 0), duration_bad=if(isnum(duration_bad), duration_bad, 0)\
| eval total_duration=(duration_good + duration_bad)\
| eval percent_sla=round(((duration_good / total_duration) * 100),2)\
| fields percent_sla\
| append [ | makeresults | eval percent_sla="100.00" | fields - _time ]\
| head 1
args = object_category, object, collection, object_fieldname, first_seen_fieldname
iseval = 0

# Get SLA compliance table
[trackme_get_sla(4)]
definition = `trackme_idx` source="flip_state_change_tracking" object_category="$object_category$" object="$object_freetext$" object="$object$"\
| sort limit=0 _time\
| table _time, object, object_category, result, object_previous_state, object_state\
| streamstats count as number_entry by object, object_category\
| eventstats count as number_total by object, object_category\
| eventstats range(_time) as range by object_category, object\
| eval range=if((number_entry == number_total),(now() - '_time'),range)\
| eval duration=tostring(range,"duration")\
| eval duration_good=case(((object_state == "green") OR (object_state == "info")),range)\
| eval duration_bad=case(((object_state != "green") AND (object_state != "info")),range)\
| stats sum(duration_good) as duration_good, sum(duration_bad) as duration_bad by object, object_category\
| eval duration_good=if(isnum(duration_good),duration_good,0), duration_bad=if(isnum(duration_bad),duration_bad,0)\
| eval total_duration=(duration_good + duration_bad)\
| eval percent_sla=round(((duration_good / total_duration) * 100),2)\
| fields object, object_category, percent_sla\
| inputlookup append=t trackme_data_source_monitoring\
| inputlookup append=t trackme_host_monitoring\
| inputlookup append=t trackme_metric_host_monitoring\
| search object_category="$object_category$"\
| eval object=case(object_category="data_source" AND isnull(object), data_name, object_category="data_host" AND isnull(object), data_host, object_category="metric_host" AND isnull(object), metric_host, isnotnull(object), object)\
| search object="$object_freetext$" object="$object$"\
| eval monitored_state=coalesce(data_monitored_state, metric_monitored_state)\
| eval current_state=case(isnotnull(data_host_state), data_host_state, isnotnull(data_source_state), data_source_state, isnotnull(metric_host_state), metric_host_state)\
| fields object, object_category, priority, monitored_state, current_state, percent_sla\
| stats first(*) as "*" by object, object_category\
| search priority="$priority$"\
| eval percent_sla=case(isnum(percent_sla), percent_sla, match(current_state, "(orange|red)"), 0, match(current_state, "(orange|red)"), 100)\
| fillnull value=0 percent_sla\
| fields object, object_category, priority, monitored_state, percent_sla
args = object_category,object,object_freetext,priority
iseval = 0

# Get SLA compliance results for a particular object
[trackme_get_sla(2)]
definition = `trackme_idx` source="flip_state_change_tracking" (object_category="$object_category$" AND object="$object$")\
| sort limit=0 _time\
| table _time, object, object_category, result, object_previous_state, object_state\
| streamstats count as number_entry by object, object_category\
| eventstats count as number_total by object, object_category\
| eventstats range(_time) as range by object_category, object\
| eval range=if((number_entry == number_total),(now() - '_time'),range)\
| eval duration=tostring(range,"duration")\
| eval duration_good=case(((object_state == "green") OR (object_state == "info")),range)\
| eval duration_bad=case(((object_state != "green") AND (object_state != "info")),range)\
| stats sum(duration_good) as duration_good, sum(duration_bad) as duration_bad by object, object_category\
| eval duration_good=if(isnum(duration_good),duration_good,0), duration_bad=if(isnum(duration_bad),duration_bad,0)\
| eval total_duration=(duration_good + duration_bad)\
| eval percent_sla=round(((duration_good / total_duration) * 100),2)\
\
| fields object, object_category, percent_sla\
\
| inputlookup append=t trackme_data_source_monitoring where (object_category="$object_category$" AND data_name="$object$")\
| inputlookup append=t trackme_host_monitoring where (object_category="$object_category$" AND data_host="$object$")\
| inputlookup append=t trackme_metric_host_monitoring where (object_category="$object_category$" AND metric_host="$object$")\
\
| eval object=case(object_category="data_source" AND isnull(object), data_name, object_category="data_host" AND isnull(object), data_host, object_category="metric_host" AND isnull(object), metric_host, isnotnull(object), object)\
| eval monitored_state=coalesce(data_monitored_state, metric_monitored_state)\
| eval current_state=case(isnotnull(data_host_state), data_host_state, isnotnull(data_source_state), data_source_state, isnotnull(metric_host_state), metric_host_state)\
\
| fields object, object_category, priority, monitored_state, current_state, percent_sla\
\
| stats first(*) as "*" by object, object_category\
\
| eval percent_sla=case(isnum(percent_sla), percent_sla, match(current_state, "(orange|red)"), 0, match(current_state, "(orange|red)"), 100)\
| fields object, object_category, priority, monitored_state, percent_sla
args = object, object_category
iseval = 0

#
# Enrichment tags
#

[trackme_tags_default_message]
definition = eval tags =  "Tags enrichment is not configured yet, consult the configuration UI TrackMe manage and configure."
iseval = 0

# data_host_tags
[trackme_get_data_host_tags]
definition = `trackme_tags_default_message`
iseval = 0

# metric_host_tags
[trackme_get_metric_host_tags]
definition = `trackme_tags_default_message`
iseval = 0

#
# Behaviour analytic
#

# This enable / disable behaviour analytic widely, default to enabled, defined to disabled to completely switch off the features
# related to behaviour analytic
[trackme_system_enable_behaviour_analytic_mode]
definition = "enabled"
iseval = 0

# This defines the default status for behaviour analytic, true / false, where default to true
# The default status defined by this macro is handled when the entity is first added to the collection
[trackme_default_enable_behaviour_analytic]
definition = "true"
iseval = 0

# This defines the default value for the outlier detection threshold multiplier, default to 2
[trackme_default_outlier_threshold_multiplier]
definition = 4
iseval = 0

# This defines the default mode for upper bound outliers detection, by default it is disabled
[trackme_default_outlier_alert_on_upper]
definition = "false"
iseval = 0

# This defines the default period for outliers calculations
[trackme_default_outlier_period]
definition = "-7d"
iseval = 0

# Summary Investigator mstats main
[trackme_summary_investigator_mstats(1)]
definition = mstats stdev(trackme.eventcount_4h) as stdev, avg(trackme.eventcount_4h) as avg where `trackme_metrics_idx` object_category="*" object="*" enable_behaviour_analytic="true" OutlierTimePeriod="$period$" earliest="$period$" latest="now" by object_category, object\
\
| inputlookup append=t trackme_data_source_monitoring where OutlierTimePeriod="$period$"\
| inputlookup append=t trackme_host_monitoring where OutlierTimePeriod="$period$"\
\
| fields object_category object stdev avg OutlierTimePeriod OutlierMinEventCount OutlierLowerThresholdMultiplier OutlierUpperThresholdMultiplier data_name data_host\
\
| eval object=case(isnull(object) AND object_category="data_source", data_name, isnull(object) AND object_category="data_host", data_host, isnotnull(object), object)\
\
| stats first(stdev) as stdev, first(avg) as avg, first(OutlierTimePeriod) as OutlierTimePeriod, first(OutlierMinEventCount) as OutlierMinEventCount,\
first(OutlierLowerThresholdMultiplier) as OutlierLowerThresholdMultiplier, first(OutlierUpperThresholdMultiplier) as OutlierUpperThresholdMultiplier by object_category, object
args = period
iseval = 0

# Summary Investigator mstats main
[trackme_summary_investigator_mstats]
definition = mstats append=t prestats=t stdev(trackme.eventcount_4h), avg(trackme.eventcount_4h) where `trackme_metrics_idx` object_category="*" object="*" enable_behaviour_analytic="true" OutlierTimePeriod="-7d" earliest="-7d" latest="now" by object_category, object\
| stats stdev(trackme.eventcount_4h) as stdev_7d, avg(trackme.eventcount_4h) as avg_7d by object_category, object\
\
| mstats append=t prestats=t stdev(trackme.eventcount_4h), avg(trackme.eventcount_4h) where `trackme_metrics_idx` object_category="*" object="*" enable_behaviour_analytic="true" OutlierTimePeriod="-30d" earliest="-30d" latest="now" by object_category, object\
| stats first(stdev_7d) as stdev_7d, first(avg_7d) as avg_7d, stdev(trackme.eventcount_4h) as stdev_30d, avg(trackme.eventcount_4h) as avg_30d by object_category, object\
\
| mstats append=t prestats=t stdev(trackme.eventcount_4h), avg(trackme.eventcount_4h) where `trackme_metrics_idx` object_category="*" object="*" enable_behaviour_analytic="true" OutlierTimePeriod="-48h" earliest="-48h" latest="now" by object_category, object\
| stats first(stdev_7d) as stdev_7d, first(avg_7d) as avg_7d, first(stdev_30d) as stdev_30d, first(avg_30d) as avg_30d, stdev(trackme.eventcount_4h) as stdev_48h, avg(trackme.eventcount_4h) as avg_48h by object_category, object\
\
| mstats append=t prestats=t stdev(trackme.eventcount_4h), avg(trackme.eventcount_4h) where `trackme_metrics_idx` object_category="*" object="*" enable_behaviour_analytic="true" OutlierTimePeriod="-24h" earliest="-24h" latest="now" by object_category, object\
\
| stats first(stdev_7d) as stdev_7d, first(avg_7d) as avg_7d, first(stdev_30d) as stdev_30d, first(avg_30d) as avg_30d, first(stdev_48h) as stdev_48h, first(avg_48h) as avg_48h, stdev(trackme.eventcount_4h) as stdev_24h, avg(trackme.eventcount_4h) as avg_24h by object_category, object\
\
`comment("#### Once all of our stats have been loaded in a very high performing fashion, retrieve the content of the collections high performing mode ####")`\
| inputlookup append=t trackme_data_source_monitoring\
| inputlookup append=t trackme_host_monitoring\
\
`comment("#### Merge them all ####")`\
| fields object_category object stdev_7d avg_7d stdev_30d avg_30d stdev_48h avg_48h stdev_24h avg_24h OutlierTimePeriod OutlierMinEventCount OutlierLowerThresholdMultiplier OutlierUpperThresholdMultiplier data_name data_host\
| eval object=case(isnull(object) AND object_category="data_source", data_name, isnull(object) AND object_category="data_host", data_host, isnotnull(object), object)\
| stats first(stdev_7d) as stdev_7d, first(avg_7d) as avg_7d, first(stdev_30d) as stdev_30d, first(avg_30d) as avg_30d, first(stdev_48h) as stdev_48h, first(avg_48h) as avg_48h, first(stdev_24h) as stdev_24h, first(avg_24h) as avg_24h,\
first(OutlierTimePeriod) as OutlierTimePeriod, first(OutlierMinEventCount) as OutlierMinEventCount,\
first(OutlierLowerThresholdMultiplier) as OutlierLowerThresholdMultiplier, first(OutlierUpperThresholdMultiplier) as OutlierUpperThresholdMultiplier by object_category, object\
\
`comment("#### Conditionally define the stdev and avg to be applied ####")`\
| eval stdev=case(\
OutlierTimePeriod="-24h", stdev_24h,\
OutlierTimePeriod="-48h", stdev_48h,\
OutlierTimePeriod="-7d", stdev_7d,\
OutlierTimePeriod="-30d", stdev_30d)\
| eval avg=case(\
OutlierTimePeriod="-24h", avg_24h,\
OutlierTimePeriod="-48h", avg_48h,\
OutlierTimePeriod="-7d", avg_7d,\
OutlierTimePeriod="-30d", avg_30d)
iseval = 0

# Summary Investigator mstats main
[trackme_summary_investigator_mstats(2)]
definition = mstats stdev(trackme.eventcount_4h) as stdev_7d, avg(trackme.eventcount_4h) as avg_7d where `trackme_metrics_idx` object_category="$object_category$" object="$object$" enable_behaviour_analytic="true" OutlierTimePeriod="-7d" earliest="-7d" latest="now" by object_category, object\
\
| append [\
| mstats stdev(trackme.eventcount_4h) as stdev_30d, avg(trackme.eventcount_4h) as avg_30d where `trackme_metrics_idx` object_category="$object_category$" object="$object$" enable_behaviour_analytic="true" OutlierTimePeriod="-30d" earliest="-30d" latest="now" by object_category, object\
]\
\
| append [\
| mstats stdev(trackme.eventcount_4h) as stdev_48h, avg(trackme.eventcount_4h) as avg_48h where `trackme_metrics_idx` object_category="$object_category$" object="$object$" enable_behaviour_analytic="true" OutlierTimePeriod="-48h" earliest="-48h" latest="now" by object_category, object\
]\
| append [\
| mstats stdev(trackme.eventcount_4h) as avg_48h, avg(trackme.eventcount_4h) as avg_24h where `trackme_metrics_idx` object_category="$object_category$" object="$object$" enable_behaviour_analytic="true" OutlierTimePeriod="-24h" earliest="-24h" latest="now" by object_category, object\
]\
\
`comment("#### Once all of our stats have been loaded in a very high performing fashion, retrieve the content of the collections high performing mode ####")`\
| inputlookup append=t trackme_data_source_monitoring\
| inputlookup append=t trackme_host_monitoring\
\
`comment("#### Merge them all ####")`\
| fields object_category object stdev_7d avg_7d stdev_30d avg_30d stdev_48h avg_48h stdev_24h avg_24h OutlierTimePeriod OutlierMinEventCount OutlierLowerThresholdMultiplier OutlierUpperThresholdMultiplier data_name data_host\
| eval object=case(isnull(object) AND object_category="data_source", data_name, isnull(object) AND object_category="data_host", data_host, isnotnull(object), object)\
| where object_category="$object_category$" AND object="$object$"\
| stats first(stdev_7d) as stdev_7d, first(avg_7d) as avg_7d, first(stdev_30d) as stdev_30d, first(avg_30d) as avg_30d, first(stdev_48h) as stdev_48h, first(avg_48h) as avg_48h, first(stdev_24h) as stdev_24h, first(avg_24h) as avg_24h,\
first(OutlierTimePeriod) as OutlierTimePeriod, first(OutlierMinEventCount) as OutlierMinEventCount,\
first(OutlierLowerThresholdMultiplier) as OutlierLowerThresholdMultiplier, first(OutlierUpperThresholdMultiplier) as OutlierUpperThresholdMultiplier by object_category, object\
\
`comment("#### Conditionally define the stdev and avg to be applied ####")`\
| eval stdev=case(\
OutlierTimePeriod="-24h", stdev_24h,\
OutlierTimePeriod="-48h", stdev_48h,\
OutlierTimePeriod="-7d", stdev_7d,\
OutlierTimePeriod="-30d", stdev_30d)\
| eval avg=case(\
OutlierTimePeriod="-24h", avg_24h,\
OutlierTimePeriod="-48h", avg_48h,\
OutlierTimePeriod="-7d", avg_7d,\
OutlierTimePeriod="-30d", avg_30d)
args = object_category, object
iseval = 0

# Summary Investigator abstract
[trackme_summary_investigator_define_bound_abstract]
definition = `comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact(OutlierLowerThresholdMultiplier)), upperBound=(avg+stdev*exact(OutlierUpperThresholdMultiplier))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(isnum(OutlierMinEventCount) AND OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### Manage OutlierMinEventCount ####")`\
| eval OutlierMinEventCount=if(isnum(OutlierMinEventCount), OutlierMinEventCount, "-1")\
\
`comment("#### Store current time ####")`\
| eval update_time=now()
iseval = 0

# Summary Investigator abstract
[trackme_summary_investigator_abstract]
definition = `comment("#### Lookup outlier configuration ####")`\
| lookup trackme_data_source_monitoring data_name as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
| lookup trackme_host_monitoring data_host as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Restrict calculations to the OutlierTimePeriod ####")`\
| eval data_eventcount=if(_time>=relative_time(now(), OutlierTimePeriod), data_eventcount, "")\
\
`comment("#### Perform standard deviation calculation of event counts registered ####")`\
| eventstats avg("data_eventcount") as avg stdev("data_eventcount") as stdev by object_category, object\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact(OutlierLowerThresholdMultiplier)), upperBound=(avg+stdev*exact(OutlierUpperThresholdMultiplier))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(isnum(OutlierMinEventCount) AND OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### In the context of event count behaviour analytic, we care about outliers that are bellow the lower bound detection ####")`\
| eval OutlierMinEventCount=if(isnum(OutlierMinEventCount), OutlierMinEventCount, "-1")\
| eval isOutlier=if('data_eventcount' < lowerBound OR 'data_eventcount' < OutlierMinEventCount, 1, 0)\
`comment("#### Define status regarding upperBound ####")`\
| eval isOutlier=if('data_eventcount' > upperBound AND match(OutlierAlertOnUpper, "^true$"), 1, isOutlier)\
\
`comment("#### Register the latest values ####")`\
| stats max(data_tracker_runtime) as data_tracker_runtime, latest(isOutlier) as isOutlier,\
first(OutlierTimePeriod) as OutlierTimePeriod,\
first(OutlierMinEventCount) as OutlierMinEventCount,\
first(OutlierLowerThresholdMultiplier) as OutlierLowerThresholdMultiplier, first(OutlierUpperThresholdMultiplier) as OutlierUpperThresholdMultiplier,\
first(OutlierAlertOnUpper) as OutlierAlertOnUpper,\
first(enable_behaviour_analytic) as enable_behaviour_analytic\
latest(lowerBound) as lowerBound, latest(upperBound) as upperBound, latest(stdev) as stdev by object_category, object\
\
`comment("#### Store current time ####")`\
| eval update_time=now()
iseval = 0

# Define the isOutlier status based on the data
[trackme_isOutlier_status]
definition = eval isOutlier=if('data_eventcount' < lowerBound OR 'data_eventcount' < OutlierMinEventCount, 1, 0)\
`comment("#### Define status regarding upperBound ####")`\
| eval isOutlier=if('data_eventcount' > upperBound AND match(OutlierAlertOnUpper, "^true$"), 1, isOutlier)
iseval = 0

# outlier chart
[trackme_outlier_chart(4)]
definition = mstats max(_value) as eventcount_4h_span where `trackme_metrics_idx` metric_name=trackme.eventcount_4h object_category="$object_category$" object="$object$" by object_category, object span=$span$\
\
`comment("#### Positive numerical only ####")`\
| where eventcount_4h_span>0\
\
`comment("#### Lookup outliers ####")`\
| lookup trackme_summary_investigator_volume_outliers object_category, object OUTPUTNEW lowerBound, upperBound\
\
`comment("#### Finally, provides the results ####")`\
| eval _split_by="$key$"\
| table _time, "eventcount_4h_span", lowerBound, upperBound
args = object_category, object, key, span
iseval = 0

# outlier table
[trackme_outlier_table(3)]
definition = inputlookup $collection$ where $key$="$object$"\
| lookup trackme_summary_investigator_volume_outliers object_category, object as $key$, OutlierTimePeriod OUTPUTNEW lowerBound, upperBound, stdev, avg\
| fields enable_behaviour_analytic, OutlierTimePeriod, OutlierSpan, isOutlier, OutlierMinEventCount, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, lowerBound, upperBound, stdev, avg\
| foreach lowerBound, upperBound, stdev avg [ eval <<FIELD>> = round('<<FIELD>>', 2) ]\
| rename enable_behaviour_analytic as "enable outlier", OutlierLowerThresholdMultiplier as "lower multiplier", OutlierUpperThresholdMultiplier as "upper multiplier", OutlierAlertOnUpper as "alert on upper"\
| foreach lowerBound upperBound stdev avg [ eval <<FIELD>> = case(\
'<<FIELD>>' > 1000000, tostring(round(('<<FIELD>>'/1000000), 2), "commas") . "M",\
'<<FIELD>>' > 1000, tostring(round(('<<FIELD>>'/1000), 2), "commas") . "K",\
isnum('<<FIELD>>'), '<<FIELD>>',\
isnotnull('<<FIELD>>') OR '<<FIELD>>'="", "error") ]
args = collection, key, object

# outlier chart
[trackme_outlier_chart_simulate(7)]
definition = mstats max(_value) as eventcount_4h_span where `trackme_metrics_idx` metric_name=trackme.eventcount_4h object_category="$object_category$" object="$object$" by object_category, object span=$span$\
`comment("#### Summary data is loaded ####")`\
\
`comment("#### Positive numerical only ####")`\
| where eventcount_4h_span>0\
\
`comment("#### Perform standard deviation calculation of event counts registered ####")`\
| append [ | mstats stdev(trackme.eventcount_4h) as stdev, avg(trackme.eventcount_4h) as avg where `trackme_metrics_idx` object_category="$object_category$" object="$object$" by object_category, object ]\
| eventstats first(stdev) as stdev, first(avg) as avg by object_category, object\
| stats first(eventcount_4h_span) as eventcount_4h_span, first(stdev) as stdev, first(avg) as avg by _time\
\
`comment("#### Define OutlierMinEventCount ####")`\
| eval OutlierMinEventCount=if(isnum($mineventcount$), $mineventcount$, -1)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact($minmultiplier$)), upperBound=(avg+stdev*exact($uppermultiplier$))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### In the context of event count behaviour analytic, we care about outliers that are bellow the lower bound detection ####")`\
| eval isOutlier=if('data_eventcount' < lowerBound, 1, 0)\
| eval isOutlier=if('data_eventcount' > upperBound, 1, isOutlier)\
\
`comment("#### Finally, provides the results ####")`\
| eval _split_by="$key$"\
| table _time, "eventcount_4h_span", lowerBound, upperBound
args = object_category, object, key, minmultiplier, uppermultiplier, mineventcount, span
iseval = 0

# Generate and mcollect when OutlierTimePeriod is changed
[trackme_outliers_gen_metrics(3)]
definition = mstats max(trackme.eventcount_4h) as trackme.eventcount_4h where `trackme_metrics_idx` object_category="$object_category$" object="$object$" enable_behaviour_analytic="true" earliest="-30d" latest="now" by object_category, object, OutlierTimePeriod span=5m\
| eval enable_behaviour_analytic="true", OutlierTimePeriod="$TargetOutlierTimePeriod$"\
| append [ | mstats max(trackme.eventcount_4h) as trackme.eventcount_4h where `trackme_metrics_idx` object_category="$object_category$" object="$object$" enable_behaviour_analytic="true" OutlierTimePeriod="$TargetOutlierTimePeriod$" earliest="-30d" latest="now" by object_category, object, OutlierTimePeriod span=5m ]\
| sort limit=0 _time\
| eventstats count as dcount by _time, object_category, object\
| where dcount=1 | fields - dcount\
| mcollect split=t `trackme_metrics_idx` object_category, object, OutlierTimePeriod, enable_behaviour_analytic
args = object_category, object, TargetOutlierTimePeriod
iseval = 0

#
# outputlookup macros from trackers
#

[trackme_outputlookup(2)]
definition = outputlookup $collection$ append=t key_field=$key$
args = collection, key
iseval = 0

#
# collect to summary index
#

[trackme_sumarycollect(1)]
definition = eval _time=now() | collect `trackme_idx` source=$report$
args = report
iseval = 0

#
# mcollect macro
#

[trackme_mcollect(4)]
definition = eval _time=now(), object=$object$, object_category="$object_category$"\
| eval $metrics$\
| fields $dimensions$, metric_name:*\
| rename "metric_name:*" as "*"\
| mcollect split=t `trackme_metrics_idx` $dimensions$
args = object, object_category, metrics, dimensions
iseval = 0

#
# Various
#

[trackme_donut_alert_by_type(1)]
definition = eval color=case(\
$key$="green", "#77dd77",\
$key$="blue", "#779ecb",\
$key$="orange", "#ffb347",\
$key$="red - other priority", "#ff6961",\
$key$="red - high priority", "#c23b22")\
| eval order=case(\
$key$="green", 0,\
$key$="blue", 1,\
$key$="orange", 2,\
$key$="red - other priority", 3,\
$key$="red - other priority", 4)\
| sort order | fields - order
args = key
iseval = 0

[trackme_donut_alert_by_priority]
definition = eval color=case(\
priority="low", "#cce5ff",\
priority="medium", "#7fbfff",\
priority="high", "#3298ff")\
| eval order=case(\
priority="low", 0,\
priority="medium", 1,\
priority="high", 2)\
| sort order | fields - order
iseval = 0

# used to generate SPL for simulation
[trackme_eval_spl]
definition = eval spl=case(\
search_mode="tstats", "| " . search_mode . " max(_indextime) as data_last_ingest, min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, count as data_eventcount" . " where " . search_constraint . " | eval data_name=\"" . data_name . "\", data_index=\"" . elastic_data_index . "\", data_sourcetype=\"" . elastic_data_sourcetype . "\", data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen",\
search_mode="raw", search_constraint . " | stats max(_indextime) as data_last_ingest, min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, count as data_eventcount" . " | eval data_name=\"" . data_name . "\", data_index=\"" . elastic_data_index . "\", data_sourcetype=\"" . elastic_data_sourcetype . "\", data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen",\
search_mode="from", "| " . search_mode . " " . from_part1 . " | " . from_part2 . " | stats max(_indextime) as data_last_ingest, min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, count as data_eventcount" . " | eval data_name=\"" . data_name . "\", data_index=\"" . elastic_data_index . "\", data_sourcetype=\"" . elastic_data_sourcetype . "\", data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen",\
search_mode="mstats", "| " . search_mode . " latest(_value) as value" . " where " . search_constraint . " by metric_name span=1s | stats min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, dc(metric_name) as data_eventcount | eval data_name=\"" . data_name . "\", data_index=\"" . elastic_data_index . "\", data_sourcetype=\"" . elastic_data_sourcetype . "\", data_last_ingest=data_last_time_seen, data_last_ingestion_lag_seen=now()-data_last_time_seen"\
)
iseval = 0

# used to simulate elastic sources
[trackme_elastic_sources_simulate(1)]
definition = rex field=search_constraint "^(?<from_part1>[^\|]*)\|(?<from_part2>.*)"\
| `trackme_eval_spl` | fields spl | eval prefix="| append [ ", eval suffix=" ]"\
| streamstats count as line_count\
| eval spl = if(line_count!=1, prefix . spl . suffix, spl)\
| fields spl\
| stats list(spl) AS spl\
| eval spl=mvjoin(spl, " ")\
| append [ | makeresults | eval spl=if(isnull(spl), "| makeresults", spl) | fields - _time ] | head 1 ]\
| where isnotnull(data_name) AND data_eventcount>0\
`comment("#### The macro expects a different name for the first time seen ####")`\
| rename data_first_time_seen as data_first_time_seen\
| eval data_index=if(isnull(data_index) OR data_index="none", data_name, data_index)\
| eval data_sourcetype=if(isnull(data_sourcetype) OR data_sourcetype="none", data_name, data_sourcetype)\
| eval simulation="true"\
`trackme_data_source_tracker_abstract`\
| append [ | makeresults | eval data_name="$data_name$", simulation_results="No results found, please verify your search." | fields - _time ]\
| fillnull value="Success, you can now add this new source to the shared tracker or as a dedicated tracker." simulation_results\
| lookup trackme_elastic_sources data_name OUTPUTNEW data_name as data_name_found\
| lookup trackme_elastic_sources_dedicated data_name OUTPUTNEW data_name as data_name_found\
| eval simulation_results=if(isnotnull(data_name_found), "ERROR: this data_source was found in the collection!", simulation_results)\
| eval " " = case(\
simulation_results="No results found, please verify your search.", "icon|ico_warn ico_small|icon-close|no results",\
simulation_results="ERROR: this data_source was found in the collection!", "icon|ico_error ico_small|icon-close|error",\
simulation_results="Success, you can now add this new source to the shared tracker or as a dedicated tracker.", "icon|ico_good ico_small|icon-check|success")\
| fields " ", simulation_results, data_name, data*, * | where data_name="$data_name$"\
| head 1
args = data_name
iseval = 0

# used within the UI to get search definition for elastic sources
[trackme_lookup_elastic_sources]
definition = lookup trackme_elastic_sources data_name OUTPUTNEW search_constraint as elastic_source_search_constraint, search_mode as elastic_source_search_mode\
| lookup trackme_elastic_sources_dedicated data_name OUTPUTNEW search_constraint as elastic_source_search_constraint, search_mode as elastic_source_search_mode\
| rex field=elastic_source_search_constraint "^(?<elastic_source_from_part1>[^\|]*)\|(?<elastic_source_from_part2>.*)"\
| rex field=elastic_source_search_constraint "(?P<elastic_mstats_idx>index=[\w|\*]*)(?P<elastic_mstats_filters>.*)"\
| eval elastic_mstats_idx=if(elastic_source_search_mode!="mstats", "", elastic_mstats_idx)\
| eval elastic_mstats_filters=if(elastic_source_search_mode!="mstats", "", elastic_mstats_filters)
iseval = 0

# used to complete the code of elastic dedicated trackers
[trackme_elastic_dedicated_tracker]
definition = where isnotnull(data_name) AND data_eventcount>0\
\
`comment("#### define data_last_ingestion_lag_seen ####")`\
| eval data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen\
\
`comment("#### Specific to elastic sources ####")`\
| eval data_index=if(isnull(data_index) OR data_index="none", data_name, data_index)\
| eval data_sourcetype=if(isnull(data_sourcetype) OR data_sourcetype="none", data_name, data_sourcetype)\
\
`comment("#### call the abstract macro ####")`\
`trackme_data_source_tracker_abstract`\
\
`comment("#### output flipping change status if changes ####")`\
| `trackme_get_flip(data_source_state, data_previous_source_state, data_name, trackme_audit_flip_temp_data_source_dedicated)`\
\
`comment("#### run collect and updates the KVstore ####")`\
| `trackme_outputlookup(trackme_data_source_monitoring, key)`\
| `trackme_mcollect(data_name, data_source, "metric_name:trackme.eventcount_4h=data_eventcount, metric_name:trackme.lag_event_sec=data_last_lag_seen, metric_name:trackme.lag_ingestion_sec=data_last_ingestion_lag_seen", "object_category, object, OutlierTimePeriod, enable_behaviour_analytic")`\
| stats c\
| `trackme_collect_flip(trackme_audit_flip_temp_data_source_dedicated)`
iseval = 0

[trackme_elastic_dedicated_tracker(1)]
definition = where isnotnull(data_name) AND data_eventcount>0\
\
`comment("#### define data_last_ingestion_lag_seen ####")`\
| eval data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen\
\
`comment("#### Specific to elastic sources ####")`\
| eval data_index=if(isnull(data_index) OR data_index="none", data_name, data_index)\
| eval data_sourcetype=if(isnull(data_sourcetype) OR data_sourcetype="none", data_name, data_sourcetype)\
\
`comment("#### call the abstract macro ####")`\
`trackme_data_source_tracker_abstract`\
\
| where data_name="$tracker_name$"\
\
`comment("#### output flipping change status if changes ####")`\
| `trackme_get_flip(data_source_state, data_previous_source_state, data_name, trackme_audit_flip_temp_data_source_dedicated)`\
`comment("#### run collect and updates the KVstore ####")`\
| `trackme_outputlookup(trackme_data_source_monitoring, key)`\
| `trackme_mcollect(data_name, data_source, "metric_name:trackme.eventcount_4h=data_eventcount, metric_name:trackme.lag_event_sec=data_last_lag_seen, metric_name:trackme.lag_ingestion_sec=data_last_ingestion_lag_seen", "object_category, object, OutlierTimePeriod, enable_behaviour_analytic")`\
| stats c\
| `trackme_collect_flip(trackme_audit_flip_temp_data_source_dedicated)`
args = tracker_name
iseval = 0

# Data Quality - rex for extractions
[trackme_data_quality_parse]
definition = rex "Context:\s*source=(?<data_source>[^\|]*)\|host=(?<data_host>[^\|]*)\|(?<data_sourcetype>[^\|]*)\|"
iseval = 0

# Get data source tracker search for refresh entity purposes
[trackme_get_tracker_data_source(3)]
definition = rest splunk_server=local /servicesNS/-/trackme/saved/searches | search eai:acl.app="trackme" title="TrackMe - *" is_visible=1 | fields title | rename title as savedsearch_name\
| where match(savedsearch_name, "elastic tracker") AND match(savedsearch_name, "$data_name$")\
| eval savedsearch_name = "\"" . savedsearch_name . "\""\
\
`comment("#### First search for Elastic dedicated trackers ####")`\
\
`comment("#### Then searches for Elastic shared trackers ####")`\
\
| append [\
| inputlookup trackme_elastic_sources | eval keyid=_key\
| search data_name=$data_name$\
| head 1\
| streamstats count as elastic_shared_count\
| fields data_name, elastic_shared_count\
| eval savedsearch_name=if(elastic_shared_count=1, "\"TrackMe - Elastic sources shared tracker\"", savedsearch_name)\
| fields savedsearch_name\
]\
\
`comment("#### Finally search for standard data sources ####")`\
\
| append [\
| inputlookup trackme_data_source_monitoring\
| fields data_name\
| search data_name="$data_name$"\
| head 1\
| streamstats count as standard_source_count\
| fields data_name, standard_source_count\
| eval savedsearch_name=if(standard_source_count=1, "\"TrackMe - Data source entity refresh\" index=\"$index$\" sourcetype=\"$sourcetype$\" data_name=\"$data_name$\"", savedsearch_name)\
| fields savedsearch_name\
]\
\
`comment("#### There must one result exactly ####")`\
\
| head 1
args = data_name, index, sourcetype
iseval = 0
